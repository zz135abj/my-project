# ç¬¬15è¯¾ï¼šPyTorchç®€ä»‹ä¸ç¯å¢ƒæ­å»º

## ğŸ“– å­¦ä¹ ç›®æ ‡
- äº†è§£PyTorchçš„å†å²å’Œç‰¹ç‚¹
- ç†è§£PyTorchä¸å…¶ä»–æ·±åº¦å­¦ä¹ æ¡†æ¶çš„åŒºåˆ«
- æŒæ¡PyTorchçš„å®‰è£…æ–¹æ³•
- ç¼–å†™ç¬¬ä¸€ä¸ªPyTorchç¨‹åº
- å­¦ä¼šä½¿ç”¨Jupyter Notebookè¿›è¡ŒPyTorchå¼€å‘

## ğŸ“š ç†è®ºçŸ¥è¯†

### ä»€ä¹ˆæ˜¯PyTorchï¼Ÿ
PyTorchæ˜¯ç”±Facebookï¼ˆç°Metaï¼‰äººå·¥æ™ºèƒ½ç ”ç©¶å›¢é˜Ÿå¼€å‘çš„å¼€æºæ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚å®ƒå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

#### æ ¸å¿ƒç‰¹ç‚¹
1. **åŠ¨æ€è®¡ç®—å›¾**ï¼šè®¡ç®—å›¾åœ¨è¿è¡Œæ—¶æ„å»ºï¼Œä¾¿äºè°ƒè¯•
2. **Pythonicé£æ ¼**ï¼šAPIè®¾è®¡ç¬¦åˆPythonç¼–ç¨‹ä¹ æƒ¯
3. **æ˜“äºè°ƒè¯•**ï¼šå¯ä»¥ä½¿ç”¨æ ‡å‡†Pythonè°ƒè¯•å·¥å…·
4. **å¼ºå¤§çš„ç¤¾åŒºæ”¯æŒ**ï¼šæ´»è·ƒçš„å¼€å‘ç¤¾åŒºå’Œä¸°å¯Œçš„èµ„æº
5. **ç”Ÿäº§å°±ç»ª**ï¼šæ”¯æŒä»ç ”ç©¶åˆ°ç”Ÿäº§çš„å®Œæ•´æµç¨‹

#### PyTorch vs TensorFlow

| ç‰¹æ€§ | PyTorch | TensorFlow |
|------|---------|------------|
| è®¡ç®—å›¾ | åŠ¨æ€å›¾ | é™æ€å›¾ï¼ˆTF2.xä¹Ÿæ”¯æŒåŠ¨æ€å›¾ï¼‰ |
| APIé£æ ¼ | Pythonic | è‡ªæˆä½“ç³» |
| è°ƒè¯•éš¾åº¦ | å®¹æ˜“ | ç›¸å¯¹å›°éš¾ |
| å­¦ä¹ æ›²çº¿ | å¹³ç¼“ | é™¡å³­ |
| ç”Ÿäº§éƒ¨ç½² | æˆç†Ÿ | éå¸¸æˆç†Ÿ |
| ç§»åŠ¨ç«¯æ”¯æŒ | è‰¯å¥½ | ä¼˜ç§€ |

### PyTorchçš„æ ¸å¿ƒç»„ä»¶

#### 1. torch
æ ¸å¿ƒå¼ é‡åº“ï¼Œæä¾›å¤šç»´æ•°ç»„å’Œæ•°å­¦è¿ç®—åŠŸèƒ½ã€‚

#### 2. torch.autograd
è‡ªåŠ¨æ±‚å¯¼ç³»ç»Ÿï¼Œæ”¯æŒæ¢¯åº¦è®¡ç®—å’Œåå‘ä¼ æ’­ã€‚

#### 3. torch.nn
ç¥ç»ç½‘ç»œæ¨¡å—ï¼Œæä¾›æ„å»ºç¥ç»ç½‘ç»œçš„å±‚å’ŒæŸå¤±å‡½æ•°ã€‚

#### 4. torch.optim
ä¼˜åŒ–å™¨æ¨¡å—ï¼Œæä¾›å„ç§ä¼˜åŒ–ç®—æ³•ã€‚

#### 5. torch.utils
å®ç”¨å·¥å…·ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€æ¨¡å‹ä¿å­˜ç­‰åŠŸèƒ½ã€‚

## ğŸ› ï¸ ç¯å¢ƒæ­å»º

### 1. ç³»ç»Ÿè¦æ±‚
- Python 3.8-3.11
- æ“ä½œç³»ç»Ÿï¼šWindowsã€macOSã€Linux
- å†…å­˜ï¼šè‡³å°‘4GB RAMï¼ˆæ¨è8GB+ï¼‰
- æ˜¾å¡ï¼šNVIDIA GPUï¼ˆå¯é€‰ï¼Œç”¨äºCUDAåŠ é€Ÿï¼‰

### 2. å®‰è£…æ–¹æ³•

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨pipå®‰è£…ï¼ˆæ¨èï¼‰
```bash
# CPUç‰ˆæœ¬
pip install torch torchvision torchaudio

# GPUç‰ˆæœ¬ï¼ˆCUDA 11.8ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# GPUç‰ˆæœ¬ï¼ˆCUDA 12.1ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### æ–¹æ³•äºŒï¼šä½¿ç”¨condaå®‰è£…
```bash
# CPUç‰ˆæœ¬
conda install pytorch torchvision torchaudio cpuonly -c pytorch

# GPUç‰ˆæœ¬
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

### 3. éªŒè¯å®‰è£…

åˆ›å»ºä¸€ä¸ªPythonè„šæœ¬éªŒè¯å®‰è£…ï¼š

```python
import torch

print(f"PyTorchç‰ˆæœ¬ï¼š{torch.__version__}")
print(f"CUDAæ˜¯å¦å¯ç”¨ï¼š{torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬ï¼š{torch.version.cuda}")
    print(f"GPUæ•°é‡ï¼š{torch.cuda.device_count()}")
    print(f"å½“å‰GPUï¼š{torch.cuda.get_device_name(0)}")
```

### 4. Jupyter Notebookå®‰è£…

```bash
# å®‰è£…Jupyter
pip install jupyter

# å¯åŠ¨Jupyter
jupyter notebook
```

## ğŸ’» ç¬¬ä¸€ä¸ªPyTorchç¨‹åº

### åŸºç¡€å¼ é‡æ“ä½œ
```python
import torch

# åˆ›å»ºå¼ é‡
x = torch.tensor([1, 2, 3, 4])
y = torch.tensor([5, 6, 7, 8])

# åŸºæœ¬è¿ç®—
print(f"x + y = {x + y}")
print(f"x * y = {x * y}")
print(f"x çš„å¹³æ–¹ = {x ** 2}")

# åˆ›å»ºçŸ©é˜µ
matrix = torch.tensor([[1, 2], [3, 4]])
print(f"çŸ©é˜µï¼š\n{matrix}")
print(f"çŸ©é˜µå½¢çŠ¶ï¼š{matrix.shape}")
```

### GPUåŠ é€Ÿç¤ºä¾‹
```python
import torch

# æ£€æŸ¥GPUå¯ç”¨æ€§
if torch.cuda.is_available():
    # åˆ›å»ºå¼ é‡å¹¶ç§»åŠ¨åˆ°GPU
    x = torch.randn(1000, 1000)
    y = torch.randn(1000, 1000)
    
    # CPUè®¡ç®—
    import time
    start_time = time.time()
    z_cpu = torch.mm(x, y)
    cpu_time = time.time() - start_time
    
    # GPUè®¡ç®—
    x_gpu = x.cuda()
    y_gpu = y.cuda()
    start_time = time.time()
    z_gpu = torch.mm(x_gpu, y_gpu)
    gpu_time = time.time() - start_time
    
    print(f"CPUè®¡ç®—æ—¶é—´ï¼š{cpu_time:.4f}ç§’")
    print(f"GPUè®¡ç®—æ—¶é—´ï¼š{gpu_time:.4f}ç§’")
    print(f"åŠ é€Ÿæ¯”ï¼š{cpu_time/gpu_time:.2f}x")
else:
    print("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®¡ç®—")
```

## âœï¸ ç»ƒä¹ é¢˜ç›®

### ç»ƒä¹ 1ï¼šç¯å¢ƒæ£€æŸ¥
ç¼–å†™ç¨‹åºæ£€æŸ¥ä½ çš„PyTorchç¯å¢ƒã€‚

```python
import torch

# æ£€æŸ¥PyTorchç‰ˆæœ¬
print(f"PyTorchç‰ˆæœ¬ï¼š{torch.__version__}")

# æ£€æŸ¥CUDAå¯ç”¨æ€§
print(f"CUDAå¯ç”¨ï¼š{torch.cuda.is_available()}")

# å¦‚æœæœ‰GPUï¼Œæ˜¾ç¤ºGPUä¿¡æ¯
if torch.cuda.is_available():
    print(f"GPUæ•°é‡ï¼š{torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}ï¼š{torch.cuda.get_device_name(i)}")
```

### ç»ƒä¹ 2ï¼šå¼ é‡åˆ›å»ºç»ƒä¹ 
åˆ›å»ºä¸åŒç±»å‹çš„å¼ é‡ã€‚

```python
import torch

# åˆ›å»ºä¸åŒç±»å‹çš„å¼ é‡
tensor_int = torch.tensor([1, 2, 3])
tensor_float = torch.tensor([1.0, 2.0, 3.0])
tensor_zeros = torch.zeros(3, 3)
tensor_ones = torch.ones(2, 4)
tensor_random = torch.randn(2, 3)

print("æ•´æ•°å¼ é‡ï¼š", tensor_int)
print("æµ®ç‚¹å¼ é‡ï¼š", tensor_float)
print("é›¶å¼ é‡ï¼š", tensor_zeros)
print("ä¸€å¼ é‡ï¼š", tensor_ones)
print("éšæœºå¼ é‡ï¼š", tensor_random)
```

### ç»ƒä¹ 3ï¼šç®€å•è®¡ç®—
ä½¿ç”¨PyTorchè¿›è¡Œæ•°å­¦è¿ç®—ã€‚

```python
import torch

# åˆ›å»ºä¸¤ä¸ªçŸ©é˜µ
A = torch.tensor([[1, 2], [3, 4]])
B = torch.tensor([[5, 6], [7, 8]])

# çŸ©é˜µè¿ç®—
print("çŸ©é˜µAï¼š\n", A)
print("çŸ©é˜µBï¼š\n", B)
print("A + Bï¼š\n", A + B)
print("A * B (å…ƒç´ ä¹˜)ï¼š\n", A * B)
print("A @ B (çŸ©é˜µä¹˜)ï¼š\n", A @ B)
```

### ç»ƒä¹ 4ï¼šGPUåŠ é€Ÿæµ‹è¯•
æ¯”è¾ƒCPUå’ŒGPUçš„è®¡ç®—æ€§èƒ½ã€‚

```python
import torch
import time

# åˆ›å»ºå¤§çŸ©é˜µ
size = 2000
x = torch.randn(size, size)
y = torch.randn(size, size)

# CPUè®¡ç®—
start = time.time()
z_cpu = torch.mm(x, y)
cpu_time = time.time() - start
print(f"CPUè®¡ç®—æ—¶é—´ï¼š{cpu_time:.4f}ç§’")

# GPUè®¡ç®—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
if torch.cuda.is_available():
    x_gpu = x.cuda()
    y_gpu = y.cuda()
    
    start = time.time()
    z_gpu = torch.mm(x_gpu, y_gpu)
    torch.cuda.synchronize()  # ç­‰å¾…GPUå®Œæˆ
    gpu_time = time.time() - start
    print(f"GPUè®¡ç®—æ—¶é—´ï¼š{gpu_time:.4f}ç§’")
    print(f"åŠ é€Ÿæ¯”ï¼š{cpu_time/gpu_time:.2f}x")
else:
    print("GPUä¸å¯ç”¨")
```

## ğŸ¯ æŒ‘æˆ˜ä»»åŠ¡

ç¼–å†™ä¸€ä¸ªPyTorchç¨‹åºï¼Œå®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š
1. åˆ›å»ºä¸€ä¸ª5x5çš„éšæœºçŸ©é˜µ
2. è®¡ç®—çŸ©é˜µçš„è½¬ç½®
3. è®¡ç®—çŸ©é˜µçš„è¡Œåˆ—å¼
4. å¯¹çŸ©é˜µè¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£
5. æ¯”è¾ƒCPUå’ŒGPUçš„è®¡ç®—æ—¶é—´

```python
import torch
import time

def matrix_operations_demo():
    print("=== PyTorchçŸ©é˜µæ“ä½œæ¼”ç¤º ===")
    
    # åˆ›å»º5x5éšæœºçŸ©é˜µ
    matrix = torch.randn(5, 5)
    print(f"åŸå§‹çŸ©é˜µï¼š\n{matrix}")
    
    # è®¡ç®—è½¬ç½®
    transpose = matrix.T
    print(f"\nè½¬ç½®çŸ©é˜µï¼š\n{transpose}")
    
    # è®¡ç®—è¡Œåˆ—å¼
    det = torch.det(matrix)
    print(f"\nè¡Œåˆ—å¼ï¼š{det:.6f}")
    
    # å¥‡å¼‚å€¼åˆ†è§£
    U, S, V = torch.svd(matrix)
    print(f"\nå¥‡å¼‚å€¼ï¼š{S}")
    
    # GPUæ€§èƒ½æµ‹è¯•
    if torch.cuda.is_available():
        large_matrix = torch.randn(1000, 1000)
        
        # CPUæµ‹è¯•
        start = time.time()
        cpu_result = torch.mm(large_matrix, large_matrix.T)
        cpu_time = time.time() - start
        
        # GPUæµ‹è¯•
        gpu_matrix = large_matrix.cuda()
        start = time.time()
        gpu_result = torch.mm(gpu_matrix, gpu_matrix.T)
        torch.cuda.synchronize()
        gpu_time = time.time() - start
        
        print(f"\nCPUè®¡ç®—æ—¶é—´ï¼š{cpu_time:.4f}ç§’")
        print(f"GPUè®¡ç®—æ—¶é—´ï¼š{gpu_time:.4f}ç§’")
        print(f"GPUåŠ é€Ÿæ¯”ï¼š{cpu_time/gpu_time:.2f}x")

# è¿è¡Œæ¼”ç¤º
matrix_operations_demo()
```

## ğŸ“ å­¦ä¹ ç¬”è®°

è¯·è®°å½•ä»¥ä¸‹å†…å®¹ï¼š
1. PyTorchçš„ä¸»è¦ç‰¹ç‚¹å’Œä¼˜åŠ¿
2. å®‰è£…è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ³•
3. PyTorchä¸TensorFlowçš„åŒºåˆ«
4. GPUåŠ é€Ÿçš„é‡è¦æ€§

## ğŸ”— æ‰©å±•é˜…è¯»

- [PyTorchå®˜æ–¹æ•™ç¨‹](https://pytorch.org/tutorials/)
- [PyTorch 60åˆ†é’Ÿå…¥é—¨](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/stable/)

---

**ä¸‹èŠ‚è¯¾é¢„å‘Š**ï¼šå¼ é‡åŸºç¡€ - æ·±å…¥å­¦ä¹ PyTorchçš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼šå¼ é‡ã€‚
